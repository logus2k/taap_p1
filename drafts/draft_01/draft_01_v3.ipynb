{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888e9661",
   "metadata": {},
   "source": [
    "# Draft_01_v3\n",
    "\n",
    "**Course:** Advanced Topics in Deep Learning  \n",
    "**Topic:** Generative Adversarial Networks (GANs)  \n",
    "**Authors:** AntÃ³nio Cruz (140129), CÃ¡tia BrÃ¡s (), Ricardo Kayseller (95813)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf50d1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60594529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required dependencies\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn.utils import spectral_norm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.kid import KernelInceptionDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9a33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "LIVE_MONITOR = True\n",
    "EMIT_INTERVAL = 1\n",
    "\n",
    "DATASET_PATH = \"../../dataset/\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 100\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "NUM_STEPS = 15005\n",
    "SAVE_INTERVAL = 1000\n",
    "\n",
    "# Loss function strategy: \"bce\", \"lsgan\", \"hinge\", \"wgan-gp\"\n",
    "LOSS_STRATEGY = \"wgan-gp\"\n",
    "\n",
    "# TTUR: Two Time-Scale Update Rule\n",
    "# D learns faster than G, so we use different learning rates\n",
    "LR_D = 4e-4  # Discriminator learning rate\n",
    "LR_G = 1e-4  # Generator learning rate (4x slower)\n",
    "\n",
    "# Adam betas optimized for GAN training\n",
    "# Lower Î²1 (0.5 vs default 0.9) reduces momentum, stabilizes adversarial updates\n",
    "ADAM_BETAS = (0.5, 0.999)\n",
    "\n",
    "# Label smoothing for BCE/LSGAN (use 0.9 instead of 1.0 for real labels)\n",
    "LABEL_SMOOTHING_REAL = 0.9\n",
    "\n",
    "# WGAN-GP: number of critic steps per generator step\n",
    "N_CRITIC = 5\n",
    "\n",
    "MODEL_OUTPUT_PATH = \"model/\"\n",
    "D_MODEL_NAME = \"D_DRAFT_01\"\n",
    "G_MODEL_NAME = \"G_DRAFT_01\"\n",
    "\n",
    "NUM_EVAL_SAMPLES = 10000\n",
    "\n",
    "# Strategies to benchmark\n",
    "BENCHMARK_STRATEGIES = [\"bce\", \"lsgan\", \"hinge\", \"wgan-gp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ee88aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gan_monitor] Live monitor at http://localhost:8992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gan_monitor] Client connected: 1JEj7OVmw0UGNCg-AAAB\n",
      "[gan_monitor] Client connected: sOUgczgD1krSKU05AAAD\n"
     ]
    }
   ],
   "source": [
    "if LIVE_MONITOR:\n",
    "    from bin.gan_monitor import (\n",
    "        start_server, emit_frames, emit_done,\n",
    "        emit_benchmark_start, emit_strategy_start, emit_strategy_end\n",
    "    )\n",
    "    start_server(port=8992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0450e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility across both numpy and pytorch\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910b60dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Use GPU if available, otherwise fall back to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5228abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Strategies\n",
    "\n",
    "class GANLossStrategy(ABC):\n",
    "    \"\"\"Base class for GAN loss strategies.\"\"\"\n",
    "    use_sigmoid: bool = True\n",
    "    use_label_smoothing: bool = False  # only BCE/LSGAN use this\n",
    "    n_critic: int = 1  # D steps per G step\n",
    "    smooth_real: float = 1.0\n",
    "    \n",
    "    @abstractmethod\n",
    "    def d_loss_real(self, output: Tensor) -> Tensor:\n",
    "        \"\"\"Discriminator loss for real images.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def d_loss_fake(self, output: Tensor) -> Tensor:\n",
    "        \"\"\"Discriminator loss for fake images.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def g_loss(self, output: Tensor) -> Tensor:\n",
    "        \"\"\"Generator loss.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def gradient_penalty(self, real_imgs: Tensor, fake_imgs: Tensor, labels: Tensor) -> Tensor:\n",
    "        \"\"\"Gradient penalty (only used by WGAN-GP).\"\"\"\n",
    "        return torch.tensor(0.0, device=real_imgs.device)\n",
    "    \n",
    "    def set_d_model(self, d_model) -> None:\n",
    "        \"\"\"Set discriminator reference (used by WGAN-GP).\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def compute_d_loss(self, d_loss_real: Tensor, d_loss_fake: Tensor, gp: Tensor) -> Tensor:\n",
    "        \"\"\"Combine D losses. Override for strategy-specific formulas.\"\"\"\n",
    "        return 0.5 * (d_loss_real + d_loss_fake) + gp\n",
    "\n",
    "\n",
    "class BCELossStrategy(GANLossStrategy):\n",
    "    \"\"\"Binary Cross-Entropy loss (original GAN) with label smoothing.\"\"\"\n",
    "    use_sigmoid = True\n",
    "    use_label_smoothing = True\n",
    "    \n",
    "    def __init__(self, device, smooth_real: float = 0.9):\n",
    "        self.device = device\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.smooth_real = smooth_real\n",
    "        self._real_labels = None\n",
    "        self._fake_labels = None\n",
    "    \n",
    "    def _ensure_labels(self, batch_size):\n",
    "        if self._real_labels is None or self._real_labels.size(0) != batch_size:\n",
    "            self._real_labels = torch.full((batch_size, 1), self.smooth_real, device=self.device)\n",
    "            self._fake_labels = torch.zeros(batch_size, 1, device=self.device)\n",
    "    \n",
    "    def d_loss_real(self, output: Tensor) -> Tensor:\n",
    "        self._ensure_labels(output.size(0))\n",
    "        return self.criterion(output, self._real_labels)\n",
    "    \n",
    "    def d_loss_fake(self, output: Tensor) -> Tensor:\n",
    "        self._ensure_labels(output.size(0))\n",
    "        return self.criterion(output, self._fake_labels)\n",
    "    \n",
    "    def g_loss(self, output: Tensor) -> Tensor:\n",
    "        # G wants D to output 1.0 (no smoothing for G)\n",
    "        ones = torch.ones(output.size(0), 1, device=self.device)\n",
    "        return self.criterion(output, ones)\n",
    "\n",
    "\n",
    "class LSGANLossStrategy(GANLossStrategy):\n",
    "    \"\"\"Least Squares loss with label smoothing.\"\"\"\n",
    "    use_sigmoid = False\n",
    "    use_label_smoothing = True\n",
    "    \n",
    "    def __init__(self, device, smooth_real: float = 0.9):\n",
    "        self.device = device\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.smooth_real = smooth_real\n",
    "        self._real_labels = None\n",
    "        self._fake_labels = None\n",
    "    \n",
    "    def _ensure_labels(self, batch_size):\n",
    "        if self._real_labels is None or self._real_labels.size(0) != batch_size:\n",
    "            self._real_labels = torch.full((batch_size, 1), self.smooth_real, device=self.device)\n",
    "            self._fake_labels = torch.zeros(batch_size, 1, device=self.device)\n",
    "    \n",
    "    def d_loss_real(self, output: Tensor) -> Tensor:\n",
    "        self._ensure_labels(output.size(0))\n",
    "        return self.criterion(output, self._real_labels)\n",
    "    \n",
    "    def d_loss_fake(self, output: Tensor) -> Tensor:\n",
    "        self._ensure_labels(output.size(0))\n",
    "        return self.criterion(output, self._fake_labels)\n",
    "    \n",
    "    def g_loss(self, output: Tensor) -> Tensor:\n",
    "        ones = torch.ones(output.size(0), 1, device=self.device)\n",
    "        return self.criterion(output, ones)\n",
    "\n",
    "\n",
    "class HingeLossStrategy(GANLossStrategy):\n",
    "    \"\"\"Hinge loss â€” used in SAGAN, BigGAN.\"\"\"\n",
    "    use_sigmoid = False\n",
    "    \n",
    "    def d_loss_real(self, output: Tensor) -> Tensor:\n",
    "        return torch.mean(F.relu(1.0 - output))\n",
    "    \n",
    "    def d_loss_fake(self, output: Tensor) -> Tensor:\n",
    "        return torch.mean(F.relu(1.0 + output))\n",
    "    \n",
    "    def g_loss(self, output: Tensor) -> Tensor:\n",
    "        return -torch.mean(output)\n",
    "\n",
    "\n",
    "class WGANGPLossStrategy(GANLossStrategy):\n",
    "    \"\"\"Wasserstein loss with gradient penalty.\"\"\"\n",
    "    use_sigmoid = False\n",
    "    n_critic = 5  # train D 5 times per G step\n",
    "    \n",
    "    def __init__(self, lambda_gp: float = 10.0):\n",
    "        self.d_model = None\n",
    "        self.lambda_gp = lambda_gp\n",
    "    \n",
    "    def set_d_model(self, d_model) -> None:\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def d_loss_real(self, output: Tensor) -> Tensor:\n",
    "        return -torch.mean(output)\n",
    "    \n",
    "    def d_loss_fake(self, output: Tensor) -> Tensor:\n",
    "        return torch.mean(output)\n",
    "    \n",
    "    def g_loss(self, output: Tensor) -> Tensor:\n",
    "        return -torch.mean(output)\n",
    "    \n",
    "    def gradient_penalty(self, real_imgs: Tensor, fake_imgs: Tensor, labels: Tensor) -> Tensor:\n",
    "        if self.d_model is None:\n",
    "            raise RuntimeError(\"d_model not set. Call set_d_model() first.\")\n",
    "        \n",
    "        batch_size = real_imgs.size(0)\n",
    "        \n",
    "        alpha = torch.rand(batch_size, 1, 1, 1, device=real_imgs.device)\n",
    "        interpolated = (alpha * real_imgs + (1 - alpha) * fake_imgs).requires_grad_(True)\n",
    "        \n",
    "        d_out = self.d_model(interpolated, labels)\n",
    "        \n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=d_out,\n",
    "            inputs=interpolated,\n",
    "            grad_outputs=torch.ones_like(d_out),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "        )[0]\n",
    "        \n",
    "        gradients = gradients.view(batch_size, -1)\n",
    "        gradient_norm = gradients.norm(2, dim=1)\n",
    "        \n",
    "        return self.lambda_gp * ((gradient_norm - 1) ** 2).mean()\n",
    "    \n",
    "    def compute_d_loss(self, d_loss_real: Tensor, d_loss_fake: Tensor, gp: Tensor) -> Tensor:\n",
    "        \"\"\"WGAN-GP uses d_fake - d_real + gp (no 0.5 averaging).\"\"\"\n",
    "        return d_loss_fake + d_loss_real + gp  # note: d_loss_real is already negated\n",
    "\n",
    "\n",
    "def get_loss_strategy(name: str, device) -> GANLossStrategy:\n",
    "    \"\"\"Factory function to get loss strategy by name.\"\"\"\n",
    "    strategies = {\n",
    "        \"bce\": BCELossStrategy,\n",
    "        \"lsgan\": LSGANLossStrategy,\n",
    "        \"hinge\": HingeLossStrategy,\n",
    "        \"wgan-gp\": WGANGPLossStrategy,\n",
    "    }\n",
    "    if name not in strategies:\n",
    "        raise ValueError(f\"Unknown loss strategy: {name}. Options: {list(strategies.keys())}\")\n",
    "    \n",
    "    if name == \"bce\":\n",
    "        return strategies[name](device, smooth_real=LABEL_SMOOTHING_REAL)\n",
    "    if name == \"lsgan\":\n",
    "        return strategies[name](device, smooth_real=LABEL_SMOOTHING_REAL)\n",
    "    return strategies[name]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25edd84b",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919c3c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Batches per epoch: 468\n"
     ]
    }
   ],
   "source": [
    "# Transform: convert PIL image to tensor (scales [0,255] to [0,1]),\n",
    "# then normalize to [-1, 1] range using mean=0.5, std=0.5\n",
    "# Formula: (x - 0.5) / 0.5 = 2x - 1, which maps [0,1] to [-1,1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset from a local folder\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=DATASET_PATH,\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# DataLoader handles batching, shuffling, and parallel loading\n",
    "# drop_last=True discards the final incomplete batch so every batch has exactly BATCH_SIZE samples\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716cfa9",
   "metadata": {},
   "source": [
    "## 3. Generator\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca62f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (label_embedding): Embedding(10, 100)\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=100, out_features=6272, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv1): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ps1): PixelShuffle(upscale_factor=2)\n",
      "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ps2): PixelShuffle(upscale_factor=2)\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.8, affine=True, track_running_stats=True)\n",
      "  (output_conv): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=LATENT_DIM, num_classes=NUM_CLASSES):\n",
    "        super().__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, latent_dim)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128 * 7 * 7),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Block 1: 7x7 -> 14x14\n",
    "        self.conv1 = nn.Conv2d(128, 128 * 4, kernel_size=3, padding=1)\n",
    "        self.ps1 = nn.PixelShuffle(2)\n",
    "        self.bn1 = nn.BatchNorm2d(128, momentum=0.8)\n",
    "\n",
    "        # Block 2: 14x14 -> 28x28\n",
    "        self.conv2 = nn.Conv2d(128, 64 * 4, kernel_size=3, padding=1)\n",
    "        self.ps2 = nn.PixelShuffle(2)\n",
    "        self.bn2 = nn.BatchNorm2d(64, momentum=0.8)\n",
    "\n",
    "        self.output_conv = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.apply(self._init_weights)\n",
    "        self._icnr_init(self.conv1, upscale_factor=2)\n",
    "        self._icnr_init(self.conv2, upscale_factor=2)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "            nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.normal_(m.weight, 1.0, 0.02)\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _icnr_init(self, conv_layer, upscale_factor):\n",
    "        \"\"\"Specialized initialization to prevent checkerboard/dots.\"\"\"\n",
    "        new_shape = [\n",
    "            conv_layer.out_channels // (upscale_factor**2),\n",
    "            conv_layer.in_channels,\n",
    "            conv_layer.kernel_size[0],\n",
    "            conv_layer.kernel_size[1]\n",
    "        ]\n",
    "        sub_kernel = torch.randn(new_shape) * 0.02\n",
    "        # Repeat the sub-kernel across the 'sub-pixel' channels\n",
    "        # This makes all 4 pixels in a 2x2 block start identical\n",
    "        icnr_kernel = sub_kernel.repeat_interleave(upscale_factor**2, dim=0)\n",
    "        conv_layer.weight.data.copy_(icnr_kernel)\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        label_embed = self.label_embedding(labels).squeeze(1)\n",
    "        x = self.fc(z * label_embed)\n",
    "        x = x.view(-1, 128, 7, 7)\n",
    "\n",
    "        x = F.relu(self.bn1(self.ps1(self.conv1(x))))\n",
    "        x = F.relu(self.bn2(self.ps2(self.conv2(x))))\n",
    "        return torch.tanh(self.output_conv(x))\n",
    "\n",
    "\n",
    "# Instantiate and move to device\n",
    "g_model = Generator().to(device)\n",
    "print(g_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c856fd90",
   "metadata": {},
   "source": [
    "## 4. Discriminator\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9942df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=NUM_CLASSES, use_sigmoid=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.use_sigmoid = use_sigmoid\n",
    "\n",
    "        # Embed the class label into a vector of size 28*28\n",
    "        self.label_embedding = nn.Embedding(num_classes, 28 * 28)\n",
    "\n",
    "        # Main sequential network with Spectral Normalization\n",
    "        self.model = nn.Sequential(\n",
    "            # Input is (2, 28, 28): image channel + label channel\n",
    "            spectral_norm(nn.Conv2d(2, 32, kernel_size=3, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            # Second conv block: (32, 14, 14) â†’ (64, 7, 7)\n",
    "            spectral_norm(nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            # Flatten\n",
    "            nn.Flatten(),\n",
    "\n",
    "            # Dense layers with Spectral Normalization\n",
    "            spectral_norm(nn.Linear(64 * 7 * 7, 512)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            spectral_norm(nn.Linear(512, 1)),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        batch_size = img.size(0)\n",
    "        \n",
    "        # Embed label and reshape to spatial map\n",
    "        label_embed = self.label_embedding(labels)\n",
    "        label_embed = label_embed.view(batch_size, 1, 28, 28)\n",
    "\n",
    "        # Concatenate image and label map\n",
    "        x = torch.cat([img, label_embed], dim=1)\n",
    "\n",
    "        x = self.model(x)\n",
    "        \n",
    "        if self.use_sigmoid:\n",
    "            x = torch.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d951fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    \"\"\"\n",
    "    DCGAN-style weight initialization.\n",
    "    Skip spectral_norm wrapped layers (they handle their own init).\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1 and not hasattr(m, 'weight_orig'):\n",
    "        # Conv layer without spectral norm\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif classname.find('Linear') != -1 and not hasattr(m, 'weight_orig'):\n",
    "        # Linear layer without spectral norm\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight, mean=1.0, std=0.02)\n",
    "        nn.init.zeros_(m.bias)\n",
    "    elif classname.find('Embedding') != -1:\n",
    "        nn.init.normal_(m.weight, mean=0.0, std=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb7733",
   "metadata": {},
   "source": [
    "# 5. Loss and Optimizers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24f7eea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied DCGAN weight initialization to Discriminator\n",
      "Using loss strategy: wgan-gp\n",
      "  - use_sigmoid: False\n",
      "  - n_critic: 5\n",
      "TTUR: LR_D=0.0004, LR_G=0.0001, betas=(0.5, 0.999)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate models\n",
    "g_model = Generator().to(device)  # has its own init\n",
    "d_model = Discriminator(use_sigmoid=(LOSS_STRATEGY == \"bce\")).to(device)\n",
    "\n",
    "# Apply DCGAN weight initialization only to D\n",
    "d_model.apply(weights_init)\n",
    "print(\"Applied DCGAN weight initialization to Discriminator\")\n",
    "\n",
    "# Get loss strategy\n",
    "loss_strategy = get_loss_strategy(LOSS_STRATEGY, device)\n",
    "loss_strategy.set_d_model(d_model)\n",
    "print(f\"Using loss strategy: {LOSS_STRATEGY}\")\n",
    "print(f\"  - use_sigmoid: {loss_strategy.use_sigmoid}\")\n",
    "print(f\"  - n_critic: {loss_strategy.n_critic}\")\n",
    "if loss_strategy.use_label_smoothing:\n",
    "    print(f\"  - label_smoothing: {loss_strategy.smooth_real}\")\n",
    "\n",
    "# Optimizers with TTUR\n",
    "optimizer_d = optim.Adam(d_model.parameters(), lr=LR_D, betas=ADAM_BETAS)\n",
    "optimizer_g = optim.Adam(g_model.parameters(), lr=LR_G, betas=ADAM_BETAS)\n",
    "print(f\"TTUR: LR_D={LR_D}, LR_G={LR_G}, betas={ADAM_BETAS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec7284",
   "metadata": {},
   "source": [
    "# 6. Training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a066dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gan_monitor] Benchmark started: ['bce', 'lsgan', 'hinge', 'wgan-gp']\n",
      "\n",
      "============================================================\n",
      "TRAINING: BCE\n",
      "============================================================\n",
      "\n",
      "[gan_monitor] Strategy started: bce (1/4)\n",
      "Step 0 â€” D: 0.7400, G: 0.5604\n",
      "Step 1000 â€” D: 0.5985, G: 0.9768\n",
      "Step 2000 â€” D: 0.6503, G: 0.8630\n",
      "Step 3000 â€” D: 0.6585, G: 0.8520\n",
      "Step 4000 â€” D: 0.6774, G: 0.8183\n",
      "Step 5000 â€” D: 0.6825, G: 0.8343\n",
      "Step 6000 â€” D: 0.6919, G: 0.8214\n",
      "Step 7000 â€” D: 0.6849, G: 0.8144\n",
      "Step 8000 â€” D: 0.6773, G: 0.8128\n",
      "Step 9000 â€” D: 0.6771, G: 0.7854\n",
      "Step 10000 â€” D: 0.6819, G: 0.8140\n",
      "Step 11000 â€” D: 0.6796, G: 0.8237\n",
      "Step 12000 â€” D: 0.6836, G: 0.8267\n",
      "Step 13000 â€” D: 0.6812, G: 0.8462\n",
      "Step 14000 â€” D: 0.6849, G: 0.8073\n",
      "Step 15000 â€” D: 0.6843, G: 0.8299\n",
      "\n",
      "Evaluating bce...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/logus/env/iscte/taap_p1/.venv_taap_p1/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gan_monitor] Strategy complete: bce (FID: 9.55)\n",
      "\n",
      "BCE Results:\n",
      "  FID: 9.55\n",
      "  KID: 0.0060 Â± 0.0026\n",
      "  Time: 329.8s\n",
      "\n",
      "============================================================\n",
      "TRAINING: LSGAN\n",
      "============================================================\n",
      "\n",
      "[gan_monitor] Strategy started: lsgan (2/4)\n",
      "Step 0 â€” D: 0.6722, G: 0.1807\n",
      "Step 1000 â€” D: 0.0955, G: 0.6242\n",
      "Step 2000 â€” D: 0.1736, G: 0.4338\n",
      "Step 3000 â€” D: 0.1913, G: 0.3973\n",
      "Step 4000 â€” D: 0.1824, G: 0.3514\n",
      "Step 5000 â€” D: 0.1963, G: 0.3499\n",
      "Step 6000 â€” D: 0.2023, G: 0.3386\n",
      "Step 7000 â€” D: 0.2007, G: 0.3309\n",
      "Step 8000 â€” D: 0.2007, G: 0.3185\n",
      "Step 9000 â€” D: 0.1881, G: 0.3172\n",
      "Step 10000 â€” D: 0.1903, G: 0.3323\n",
      "Step 11000 â€” D: 0.1840, G: 0.3268\n",
      "Step 12000 â€” D: 0.1923, G: 0.3042\n",
      "Step 13000 â€” D: 0.1976, G: 0.3001\n",
      "Step 14000 â€” D: 0.1951, G: 0.3116\n",
      "Step 15000 â€” D: 0.1974, G: 0.3311\n",
      "\n",
      "Evaluating lsgan...\n"
     ]
    }
   ],
   "source": [
    "# Benchmark training loop\n",
    "\n",
    "# Store results\n",
    "benchmark_results = {}\n",
    "\n",
    "def run_benchmark(strategies=BENCHMARK_STRATEGIES, num_steps=NUM_STEPS, save_interval=SAVE_INTERVAL):\n",
    "    \"\"\"\n",
    "    Run training for each loss strategy and collect metrics.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Emit benchmark start\n",
    "    if LIVE_MONITOR:\n",
    "        emit_benchmark_start(strategies, num_steps)\n",
    "    \n",
    "    for strategy_idx, strategy_name in enumerate(strategies):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"TRAINING: {strategy_name.upper()}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # Emit strategy start\n",
    "        if LIVE_MONITOR:\n",
    "            emit_strategy_start(strategy_name, strategy_idx, len(strategies))\n",
    "        \n",
    "        # Reset random seeds for fair comparison\n",
    "        np.random.seed(SEED)\n",
    "        torch.manual_seed(SEED)\n",
    "        \n",
    "        # Instantiate fresh models\n",
    "        g_model = Generator().to(device)\n",
    "        d_model = Discriminator(use_sigmoid=(strategy_name == \"bce\")).to(device)\n",
    "        d_model.apply(weights_init)\n",
    "        \n",
    "        # Get loss strategy\n",
    "        loss_strategy = get_loss_strategy(strategy_name, device)\n",
    "        loss_strategy.set_d_model(d_model)\n",
    "        \n",
    "        # Optimizers\n",
    "        optimizer_d = optim.Adam(d_model.parameters(), lr=LR_D, betas=ADAM_BETAS)\n",
    "        optimizer_g = optim.Adam(g_model.parameters(), lr=LR_G, betas=ADAM_BETAS)\n",
    "        \n",
    "        # Training state\n",
    "        losses = {\"G\": [], \"D\": []}\n",
    "        data_iter = iter(train_loader)\n",
    "        n_critic = loss_strategy.n_critic\n",
    "        d_loss = torch.tensor(0.0)\n",
    "        \n",
    "        # Fixed test samples for visualization\n",
    "        samples_test = torch.randn(16, LATENT_DIM, device=device)\n",
    "        labels_test = torch.randint(0, 10, (16, 1), device=device)\n",
    "        \n",
    "        # Timing\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for step in range(num_steps):\n",
    "            # --- Train Discriminator ---\n",
    "            for _ in range(n_critic):\n",
    "                try:\n",
    "                    real_imgs, batch_labels = next(data_iter)\n",
    "                except StopIteration:\n",
    "                    data_iter = iter(train_loader)\n",
    "                    real_imgs, batch_labels = next(data_iter)\n",
    "\n",
    "                real_imgs = real_imgs.to(device)\n",
    "                batch_labels = batch_labels.unsqueeze(1).to(device)\n",
    "\n",
    "                noise = torch.randn(BATCH_SIZE, LATENT_DIM, device=device)\n",
    "                fake_imgs = g_model(noise, batch_labels)\n",
    "\n",
    "                optimizer_d.zero_grad()\n",
    "                d_real_out = d_model(real_imgs, batch_labels)\n",
    "                d_loss_real = loss_strategy.d_loss_real(d_real_out)\n",
    "                d_fake_out = d_model(fake_imgs.detach(), batch_labels)\n",
    "                d_loss_fake = loss_strategy.d_loss_fake(d_fake_out)\n",
    "                gp = loss_strategy.gradient_penalty(real_imgs, fake_imgs.detach(), batch_labels)\n",
    "                d_loss = loss_strategy.compute_d_loss(d_loss_real, d_loss_fake, gp)\n",
    "                d_loss.backward()\n",
    "                optimizer_d.step()\n",
    "\n",
    "            # --- Train Generator ---\n",
    "            optimizer_g.zero_grad()\n",
    "            z = torch.randn(BATCH_SIZE, LATENT_DIM, device=device)\n",
    "            gen_labels = torch.randint(0, 10, (BATCH_SIZE, 1), device=device)\n",
    "            gen_imgs = g_model(z, gen_labels)\n",
    "            g_out = d_model(gen_imgs, gen_labels)\n",
    "            g_loss = loss_strategy.g_loss(g_out)\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "            losses[\"G\"].append(g_loss.item())\n",
    "            losses[\"D\"].append(d_loss.item())\n",
    "\n",
    "            if step % save_interval == 0:\n",
    "                print(f\"Step {step} â€” D: {d_loss.item():.4f}, G: {g_loss.item():.4f}\")\n",
    "\n",
    "            # Live monitor\n",
    "            if LIVE_MONITOR and step % EMIT_INTERVAL == 0:\n",
    "                with torch.no_grad():\n",
    "                    monitor_samples = g_model(samples_test, labels_test)\n",
    "                emit_frames(monitor_samples, labels_test, step, g_loss.item(), d_loss.item(), num_steps)\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        # Evaluate\n",
    "        print(f\"\\nEvaluating {strategy_name}...\")\n",
    "        fid_score, kid_mean, kid_std = evaluate_model_for_benchmark(g_model)\n",
    "        \n",
    "        # Emit strategy end with results\n",
    "        if LIVE_MONITOR:\n",
    "            emit_strategy_end(strategy_name, fid_score, kid_mean, kid_std, training_time)\n",
    "        \n",
    "        # Generate final samples\n",
    "        with torch.no_grad():\n",
    "            final_samples = g_model(samples_test, labels_test)\n",
    "        \n",
    "        # Store results\n",
    "        results[strategy_name] = {\n",
    "            \"losses\": losses,\n",
    "            \"fid\": fid_score,\n",
    "            \"kid_mean\": kid_mean,\n",
    "            \"kid_std\": kid_std,\n",
    "            \"training_time\": training_time,\n",
    "            \"g_model_state\": deepcopy(g_model.state_dict()),\n",
    "            \"d_model_state\": deepcopy(d_model.state_dict()),\n",
    "            \"final_samples\": final_samples.cpu(),\n",
    "            \"labels_test\": labels_test.cpu(),\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n{strategy_name.upper()} Results:\")\n",
    "        print(f\"  FID: {fid_score:.2f}\")\n",
    "        print(f\"  KID: {kid_mean:.4f} Â± {kid_std:.4f}\")\n",
    "        print(f\"  Time: {training_time:.1f}s\")\n",
    "    \n",
    "    # Emit benchmark complete\n",
    "    if LIVE_MONITOR:\n",
    "        emit_done()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_model_for_benchmark(g_model):\n",
    "    \"\"\"Evaluation function for benchmarking (returns values, doesn't print).\"\"\"\n",
    "    fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "    kid = KernelInceptionDistance(feature=2048, subset_size=100).to(device)\n",
    "\n",
    "    idx = np.random.randint(0, len(train_dataset), NUM_EVAL_SAMPLES)\n",
    "    batch_size = 256\n",
    "    \n",
    "    for i in range(0, NUM_EVAL_SAMPLES, batch_size):\n",
    "        batch_idx = idx[i:i + batch_size]\n",
    "        real_batch = torch.stack([train_dataset[j][0] for j in batch_idx])\n",
    "        real_batch = ((real_batch + 1) / 2 * 255).clamp(0, 255).to(torch.uint8)\n",
    "        real_batch = real_batch.repeat(1, 3, 1, 1)\n",
    "        real_batch = torch.nn.functional.interpolate(\n",
    "            real_batch.float(), size=(299, 299), mode='bilinear', align_corners=False\n",
    "        ).to(torch.uint8).to(device)\n",
    "        fid.update(real_batch, real=True)\n",
    "        kid.update(real_batch, real=True)\n",
    "\n",
    "    for i in range(0, NUM_EVAL_SAMPLES, batch_size):\n",
    "        current_batch = min(batch_size, NUM_EVAL_SAMPLES - i)\n",
    "        noise = torch.randn(current_batch, LATENT_DIM, device=device)\n",
    "        labels = torch.randint(0, 10, (current_batch, 1), device=device)\n",
    "        with torch.no_grad():\n",
    "            fake_batch = g_model(noise, labels)\n",
    "        fake_batch = ((fake_batch + 1) / 2 * 255).clamp(0, 255).to(torch.uint8)\n",
    "        fake_batch = fake_batch.repeat(1, 3, 1, 1)\n",
    "        fake_batch = torch.nn.functional.interpolate(\n",
    "            fake_batch.float(), size=(299, 299), mode='bilinear', align_corners=False\n",
    "        ).to(torch.uint8).to(device)\n",
    "        fid.update(fake_batch, real=False)\n",
    "        kid.update(fake_batch, real=False)\n",
    "\n",
    "    fid_score = fid.compute().item()\n",
    "    kid_mean, kid_std = kid.compute()\n",
    "    \n",
    "    return fid_score, kid_mean.item(), kid_std.item()\n",
    "\n",
    "\n",
    "# Run the benchmark\n",
    "benchmark_results = run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309a73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results summary table\n",
    "\n",
    "def print_results_table(results):\n",
    "    \"\"\"Print a formatted comparison table.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BENCHMARK RESULTS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"{'Strategy':<12} {'FID':>10} {'KID':>18} {'Time (s)':>12}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Sort by FID (best first)\n",
    "    sorted_results = sorted(results.items(), key=lambda x: x[1]['fid'])\n",
    "    \n",
    "    for i, (name, data) in enumerate(sorted_results):\n",
    "        rank = \"ðŸ¥‡\" if i == 0 else \"ðŸ¥ˆ\" if i == 1 else \"ðŸ¥‰\" if i == 2 else \"  \"\n",
    "        kid_str = f\"{data['kid_mean']:.4f} Â± {data['kid_std']:.4f}\"\n",
    "        print(f\"{rank} {name:<10} {data['fid']:>10.2f} {kid_str:>18} {data['training_time']:>12.1f}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Best performer\n",
    "    best = sorted_results[0]\n",
    "    print(f\"\\nâœ“ Best performer: {best[0].upper()} (FID: {best[1]['fid']:.2f})\")\n",
    "\n",
    "print_results_table(benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacfb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison visualization\n",
    "\n",
    "def plot_benchmark_comparison(results):\n",
    "    \"\"\"Create comprehensive comparison visualizations.\"\"\"\n",
    "    strategies = list(results.keys())\n",
    "    n_strategies = len(strategies)\n",
    "    \n",
    "    # Color scheme\n",
    "    colors = {'bce': '#3498db', 'lsgan': '#2ecc71', 'hinge': '#e74c3c', 'wgan-gp': '#9b59b6'}\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    # --- 1. FID Bar Chart (top left) ---\n",
    "    ax1 = fig.add_subplot(2, 3, 1)\n",
    "    x = np.arange(n_strategies)\n",
    "    width = 0.35\n",
    "    \n",
    "    fids = [results[s]['fid'] for s in strategies]\n",
    "    \n",
    "    bars1 = ax1.bar(x, fids, width*1.5, color=[colors[s] for s in strategies], alpha=0.8)\n",
    "    ax1.set_ylabel('FID (lower is better)')\n",
    "    ax1.set_title('FID Comparison')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels([s.upper() for s in strategies])\n",
    "    ax1.axhline(y=min(fids), color='green', linestyle='--', alpha=0.5, label=f'Best: {min(fids):.2f}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    for bar, val in zip(bars1, fids):\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                f'{val:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # --- 2. KID Bar Chart (top middle) ---\n",
    "    ax2 = fig.add_subplot(2, 3, 2)\n",
    "    kid_means = [results[s]['kid_mean'] for s in strategies]\n",
    "    kid_stds = [results[s]['kid_std'] for s in strategies]\n",
    "    \n",
    "    bars2 = ax2.bar(x, kid_means, width*1.5, yerr=kid_stds, capsize=5,\n",
    "                    color=[colors[s] for s in strategies], alpha=0.8)\n",
    "    ax2.set_ylabel('KID (lower is better)')\n",
    "    ax2.set_title('KID Comparison (with std)')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels([s.upper() for s in strategies])\n",
    "    \n",
    "    # --- 3. Training Time (top right) ---\n",
    "    ax3 = fig.add_subplot(2, 3, 3)\n",
    "    times = [results[s]['training_time'] for s in strategies]\n",
    "    bars3 = ax3.bar(x, times, width*1.5, color=[colors[s] for s in strategies], alpha=0.8)\n",
    "    ax3.set_ylabel('Time (seconds)')\n",
    "    ax3.set_title('Training Time')\n",
    "    ax3.set_xticks(x)\n",
    "    ax3.set_xticklabels([s.upper() for s in strategies])\n",
    "    \n",
    "    for bar, val in zip(bars3, times):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                f'{val:.0f}s', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # --- 4. Loss Curves with Dual Y-Axis (bottom left, spans 2 columns) ---\n",
    "    ax4 = fig.add_subplot(2, 3, (4, 5))\n",
    "    \n",
    "    # Smoothing function\n",
    "    def smooth(data, window=100):\n",
    "        if len(data) > window:\n",
    "            return np.convolve(data, np.ones(window)/window, mode='valid')\n",
    "        return data\n",
    "    \n",
    "    # Plot BCE, LSGAN, Hinge on left axis\n",
    "    for s in ['bce', 'lsgan', 'hinge']:\n",
    "        if s in results:\n",
    "            losses_g = results[s]['losses']['G']\n",
    "            smoothed = smooth(losses_g)\n",
    "            ax4.plot(smoothed, label=f'{s.upper()} (G)', color=colors[s], linewidth=1.5)\n",
    "    \n",
    "    ax4.set_xlabel('Step')\n",
    "    ax4.set_ylabel('Generator Loss (BCE / LSGAN / Hinge)')\n",
    "    ax4.set_ylim(-0.5, 1.5)\n",
    "    ax4.legend(loc='upper left')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.set_title('Generator Loss Curves')\n",
    "    \n",
    "    # Plot WGAN-GP on right axis\n",
    "    if 'wgan-gp' in results:\n",
    "        ax4_right = ax4.twinx()\n",
    "        losses_g = results['wgan-gp']['losses']['G']\n",
    "        smoothed = smooth(losses_g)\n",
    "        ax4_right.plot(smoothed, label='WGAN-GP (G)', color=colors['wgan-gp'], \n",
    "                       linewidth=1.5, linestyle='--')\n",
    "        ax4_right.set_ylabel('Generator Loss (WGAN-GP)', color=colors['wgan-gp'])\n",
    "        ax4_right.tick_params(axis='y', labelcolor=colors['wgan-gp'])\n",
    "        ax4_right.legend(loc='upper right')\n",
    "    \n",
    "    # --- 5. Radar/Spider Chart (bottom right) ---\n",
    "    ax5 = fig.add_subplot(2, 3, 6, projection='polar')\n",
    "    \n",
    "    max_fid = max(fids)\n",
    "    max_kid = max(kid_means)\n",
    "    max_time = max(times)\n",
    "    \n",
    "    metrics = ['FID\\nQuality', 'KID\\nQuality', 'Speed']\n",
    "    n_metrics = len(metrics)\n",
    "    angles = np.linspace(0, 2 * np.pi, n_metrics, endpoint=False).tolist()\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    for s in strategies:\n",
    "        values = [\n",
    "            1 - results[s]['fid'] / max_fid,\n",
    "            1 - results[s]['kid_mean'] / max_kid,\n",
    "            1 - results[s]['training_time'] / max_time,\n",
    "        ]\n",
    "        values += values[:1]\n",
    "        ax5.plot(angles, values, 'o-', linewidth=2, label=s.upper(), color=colors[s])\n",
    "        ax5.fill(angles, values, alpha=0.1, color=colors[s])\n",
    "    \n",
    "    ax5.set_xticks(angles[:-1])\n",
    "    ax5.set_xticklabels(metrics)\n",
    "    ax5.set_title('Overall Comparison\\n(higher = better)')\n",
    "    ax5.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    os.makedirs('images', exist_ok=True)\n",
    "    plt.savefig('images/benchmark_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Saved: images/benchmark_comparison.png\")\n",
    "\n",
    "plot_benchmark_comparison(benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class quality analysis\n",
    "\n",
    "def analyze_per_class_quality(results, n_samples=100):\n",
    "    \"\"\"\n",
    "    Generate samples for each class and compute per-class statistics.\n",
    "    Helps identify if certain digits are harder to generate.\n",
    "    \"\"\"\n",
    "    print(\"\\nPer-Class Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    class_stats = {s: {} for s in results.keys()}\n",
    "    \n",
    "    for strategy in results.keys():\n",
    "        # Load the trained generator\n",
    "        g_model = Generator().to(device)\n",
    "        g_model.load_state_dict(results[strategy]['g_model_state'])\n",
    "        g_model.eval()\n",
    "        \n",
    "        for digit in range(10):\n",
    "            noise = torch.randn(n_samples, LATENT_DIM, device=device)\n",
    "            labels = torch.full((n_samples, 1), digit, device=device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                samples = g_model(noise, labels)\n",
    "            \n",
    "            # Compute statistics\n",
    "            mean_intensity = samples.mean().item()\n",
    "            std_intensity = samples.std().item()\n",
    "            \n",
    "            class_stats[strategy][digit] = {\n",
    "                'mean': mean_intensity,\n",
    "                'std': std_intensity,\n",
    "            }\n",
    "    \n",
    "    # Print comparison table\n",
    "    print(f\"\\n{'Digit':<8}\", end=\"\")\n",
    "    for s in results.keys():\n",
    "        print(f\"{s.upper():>12}\", end=\"\")\n",
    "    print()\n",
    "    print(\"-\" * (8 + 12 * len(results)))\n",
    "    \n",
    "    for digit in range(10):\n",
    "        print(f\"{digit:<8}\", end=\"\")\n",
    "        for s in results.keys():\n",
    "            std = class_stats[s][digit]['std']\n",
    "            print(f\"{std:>12.3f}\", end=\"\")\n",
    "        print()\n",
    "    \n",
    "    print(\"\\n(Values show standard deviation - higher = more variety)\")\n",
    "\n",
    "analyze_per_class_quality(benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a92a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated Samples Comparison Grid\n",
    "\n",
    "def plot_samples_comparison(results):\n",
    "    \"\"\"Show final generated samples from each strategy side by side.\"\"\"\n",
    "    strategies = list(results.keys())\n",
    "    n_strategies = len(strategies)\n",
    "    \n",
    "    fig, axes = plt.subplots(4, n_strategies * 4, figsize=(n_strategies * 5, 5))\n",
    "    \n",
    "    for col, strategy in enumerate(strategies):\n",
    "        samples = results[strategy]['final_samples']\n",
    "        labels = results[strategy]['labels_test']\n",
    "        \n",
    "        for i in range(16):\n",
    "            row = i // 4\n",
    "            sub_col = i % 4\n",
    "            ax = axes[row, col * 4 + sub_col]\n",
    "            \n",
    "            img = samples[i].numpy().reshape(28, 28)\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Add strategy name as title for first row\n",
    "            if i == 0:\n",
    "                ax.set_title(f'{strategy.upper()}\\n{labels[i].item()}', fontsize=10)\n",
    "            elif row == 0:\n",
    "                ax.set_title(str(labels[i].item()), fontsize=9)\n",
    "    \n",
    "    fig.suptitle('Generated Samples Comparison', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs('images', exist_ok=True)\n",
    "    plt.savefig('images/samples_comparison.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"Saved: images/samples_comparison.png\")\n",
    "\n",
    "plot_samples_comparison(benchmark_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf387195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Export benchmark results to CSV\n",
    "\n",
    "def export_results_csv(results, filename='benchmark_results.csv'):\n",
    "    \"\"\"Export benchmark results to CSV for further analysis.\"\"\"\n",
    "    import csv\n",
    "    \n",
    "    with open(filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Strategy', 'FID', 'KID_Mean', 'KID_Std', 'Training_Time_Seconds'])\n",
    "        \n",
    "        for name, data in results.items():\n",
    "            writer.writerow([\n",
    "                name,\n",
    "                f\"{data['fid']:.4f}\",\n",
    "                f\"{data['kid_mean']:.6f}\",\n",
    "                f\"{data['kid_std']:.6f}\",\n",
    "                f\"{data['training_time']:.2f}\"\n",
    "            ])\n",
    "    \n",
    "    print(f\"Results exported to {filename}\")\n",
    "\n",
    "# export_results_csv(benchmark_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22825292",
   "metadata": {},
   "source": [
    "# 8. Per-class Grid\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_per_class(g_model, rows_per_class=5, title=\"Generated Samples Per Class\"):\n",
    "    \"\"\"Generates a grid with one column per digit class (0-9).\"\"\"\n",
    "    fig, axes = plt.subplots(rows_per_class, 10, figsize=(15, 8))\n",
    "\n",
    "    for digit in range(10):\n",
    "        noise = torch.randn(rows_per_class, LATENT_DIM, device=device)\n",
    "        labels = torch.full((rows_per_class, 1), digit, device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = g_model(noise, labels)\n",
    "\n",
    "        for row in range(rows_per_class):\n",
    "            img = images[row].cpu().numpy().reshape(28, 28)\n",
    "            axes[row, digit].imshow(img, cmap='gray')\n",
    "            axes[row, digit].axis('off')\n",
    "\n",
    "            if row == 0:\n",
    "                axes[row, digit].set_title(str(digit))\n",
    "\n",
    "    fig.suptitle(title, fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot for all strategies\n",
    "for strategy_name in benchmark_results:\n",
    "    g_model = Generator().to(device)\n",
    "    g_model.load_state_dict(benchmark_results[strategy_name]['g_model_state'])\n",
    "    g_model.eval()\n",
    "    \n",
    "    plot_per_class(g_model, title=f\"Generated Samples Per Class â€” {strategy_name.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8817863c",
   "metadata": {},
   "source": [
    "# 10. Model Saving\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8507f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models(results):\n",
    "    \"\"\"Saves generator and discriminator state dicts for all strategies.\"\"\"\n",
    "    os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)\n",
    "    \n",
    "    for strategy_name, data in results.items():\n",
    "        g_path = os.path.join(MODEL_OUTPUT_PATH, f'G_{strategy_name}.pt')\n",
    "        d_path = os.path.join(MODEL_OUTPUT_PATH, f'D_{strategy_name}.pt')\n",
    "        \n",
    "        torch.save(data['g_model_state'], g_path)\n",
    "        torch.save(data['d_model_state'], d_path)\n",
    "        \n",
    "        print(f\"Saved: {g_path}, {d_path}\")\n",
    "\n",
    "save_models(benchmark_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63e5cf",
   "metadata": {},
   "source": [
    "# 11. Single-Image Inference\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a digit from 0-9\n",
    "digit = 8\n",
    "\n",
    "# Use same noise for fair comparison\n",
    "z = torch.randn(1, LATENT_DIM, device=device)\n",
    "label = torch.tensor([[digit]], device=device)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(benchmark_results), figsize=(3 * len(benchmark_results), 3))\n",
    "\n",
    "for idx, (strategy_name, data) in enumerate(benchmark_results.items()):\n",
    "    g_model = Generator().to(device)\n",
    "    g_model.load_state_dict(data['g_model_state'])\n",
    "    g_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        generated = g_model(z, label)\n",
    "    \n",
    "    img = generated[0].cpu().numpy().reshape(28, 28)\n",
    "    axes[idx].imshow(img, cmap='gray')\n",
    "    axes[idx].set_title(f\"{strategy_name.upper()}\\nFID: {data['fid']:.1f}\")\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "fig.suptitle(f\"Generated Digit: {digit}\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_taap_p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
