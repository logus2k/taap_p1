{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "888e9661",
   "metadata": {},
   "source": [
    "# Draft_01_v2\n",
    "\n",
    "**Course:** Advanced Topics in Deep Learning  \n",
    "**Topic:** Generative Adversarial Networks (GANs)  \n",
    "**Authors:** António Cruz (140129), Cátia Brás (), Ricardo Kayseller (95813)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bf50d1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60594529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.kid import KernelInceptionDistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9a33bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "LIVE_MONITOR = False\n",
    "EMIT_INTERVAL = 1\n",
    "\n",
    "DATASET_PATH = \"../../dataset/\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LATENT_DIM = 100\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "NUM_STEPS = 15005\n",
    "SAVE_INTERVAL = 1000\n",
    "\n",
    "# Loss function strategy: \"bce\", \"lsgan\", \"hinge\", \"wgan\"\n",
    "LOSS_STRATEGY = \"bce\"\n",
    "\n",
    "MODEL_OUTPUT_PATH = \"model/\"\n",
    "D_MODEL_NAME = \"D_DRAFT_01\"\n",
    "G_MODEL_NAME = \"G_DRAFT_01\"\n",
    "\n",
    "NUM_EVAL_SAMPLES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0450e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility across both numpy and pytorch\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b60dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available, otherwise fall back to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Strategies\n",
    "\n",
    "class GANLossStrategy(ABC):\n",
    "    \"\"\"Base class for GAN loss strategies.\"\"\"\n",
    "    use_sigmoid: bool = True\n",
    "    \n",
    "    @abstractmethod\n",
    "    def d_loss_real(self, output: Tensor) -> Tensor:\n",
    "        \"\"\"Discriminator loss for real images.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def d_loss_fake(self, output: Tensor) -> Tensor:\n",
    "        \"\"\"Discriminator loss for fake images.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def g_loss(self, output: Tensor) -> Tensor:\n",
    "        \"\"\"Generator loss.\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class BCELossStrategy(GANLossStrategy):\n",
    "    \"\"\"Binary Cross-Entropy loss (original GAN).\"\"\"\n",
    "    use_sigmoid = True\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self._ones = None\n",
    "        self._zeros = None\n",
    "    \n",
    "    def _ensure_labels(self, batch_size):\n",
    "        if self._ones is None or self._ones.size(0) != batch_size:\n",
    "            self._ones = torch.ones(batch_size, 1, device=self.device)\n",
    "            self._zeros = torch.zeros(batch_size, 1, device=self.device)\n",
    "    \n",
    "    def d_loss_real(self, output):\n",
    "        self._ensure_labels(output.size(0))\n",
    "        return self.criterion(output, self._ones)\n",
    "    \n",
    "    def d_loss_fake(self, output):\n",
    "        self._ensure_labels(output.size(0))\n",
    "        return self.criterion(output, self._zeros)\n",
    "    \n",
    "    def g_loss(self, output):\n",
    "        self._ensure_labels(output.size(0))\n",
    "        return self.criterion(output, self._ones)\n",
    "\n",
    "\n",
    "class LSGANLossStrategy(GANLossStrategy):\n",
    "    \"\"\"Least Squares loss — often more stable than BCE.\"\"\"\n",
    "    use_sigmoid = False\n",
    "    \n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self._ones = None\n",
    "        self._zeros = None\n",
    "    \n",
    "    def _ensure_labels(self, batch_size):\n",
    "        if self._ones is None or self._ones.size(0) != batch_size:\n",
    "            self._ones = torch.ones(batch_size, 1, device=self.device)\n",
    "            self._zeros = torch.zeros(batch_size, 1, device=self.device)\n",
    "    \n",
    "    def d_loss_real(self, output):\n",
    "        self._ensure_labels(output.size(0))\n",
    "        return self.criterion(output, self._ones)\n",
    "    \n",
    "    def d_loss_fake(self, output):\n",
    "        self._ensure_labels(output.size(0))\n",
    "        return self.criterion(output, self._zeros)\n",
    "    \n",
    "    def g_loss(self, output):\n",
    "        self._ensure_labels(output.size(0))\n",
    "        return self.criterion(output, self._ones)\n",
    "\n",
    "\n",
    "class HingeLossStrategy(GANLossStrategy):\n",
    "    \"\"\"Hinge loss — used in SAGAN, BigGAN.\"\"\"\n",
    "    use_sigmoid = False\n",
    "    \n",
    "    def d_loss_real(self, output):\n",
    "        return torch.mean(F.relu(1.0 - output))\n",
    "    \n",
    "    def d_loss_fake(self, output):\n",
    "        return torch.mean(F.relu(1.0 + output))\n",
    "    \n",
    "    def g_loss(self, output):\n",
    "        return -torch.mean(output)\n",
    "\n",
    "\n",
    "class WGANLossStrategy(GANLossStrategy):\n",
    "    \"\"\"Wasserstein loss — requires weight clipping or gradient penalty.\"\"\"\n",
    "    use_sigmoid = False\n",
    "    \n",
    "    def d_loss_real(self, output):\n",
    "        return -torch.mean(output)\n",
    "    \n",
    "    def d_loss_fake(self, output):\n",
    "        return torch.mean(output)\n",
    "    \n",
    "    def g_loss(self, output):\n",
    "        return -torch.mean(output)\n",
    "\n",
    "\n",
    "def get_loss_strategy(name: str, device) -> GANLossStrategy:\n",
    "    \"\"\"Factory function to get loss strategy by name.\"\"\"\n",
    "    strategies = {\n",
    "        \"bce\": BCELossStrategy,\n",
    "        \"lsgan\": LSGANLossStrategy,\n",
    "        \"hinge\": HingeLossStrategy,\n",
    "        \"wgan\": WGANLossStrategy,\n",
    "    }\n",
    "    if name not in strategies:\n",
    "        raise ValueError(f\"Unknown loss strategy: {name}. Options: {list(strategies.keys())}\")\n",
    "    \n",
    "    # BCE and LSGAN need device for label tensors\n",
    "    if name in (\"bce\", \"lsgan\"):\n",
    "        return strategies[name](device)\n",
    "    return strategies[name]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25edd84b",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c3c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform: convert PIL image to tensor (scales [0,255] to [0,1]),\n",
    "# then normalize to [-1, 1] range using mean=0.5, std=0.5\n",
    "# Formula: (x - 0.5) / 0.5 = 2x - 1, which maps [0,1] to [-1,1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset from a local folder\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=DATASET_PATH,\n",
    "    train=True,\n",
    "    download=False,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# DataLoader handles batching, shuffling, and parallel loading\n",
    "# drop_last=True discards the final incomplete batch so every batch has exactly BATCH_SIZE samples\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Batches per epoch: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716cfa9",
   "metadata": {},
   "source": [
    "## 3. Generator\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca62f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, latent_dim=LATENT_DIM, num_classes=NUM_CLASSES):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Embed the class label into a vector of the same size as z: input_dim=10, output_dim=latent_dim\n",
    "        self.label_embedding = nn.Embedding(num_classes, latent_dim)\n",
    "\n",
    "        # Main sequential network that transforms the conditioned noise into an image\n",
    "        self.model = nn.Sequential(\n",
    "            # Dense layer: latent_dim → 128*7*7\n",
    "            nn.Linear(latent_dim, 128 * 7 * 7),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Reshape handled via forward(); here we continue from (128, 7, 7)\n",
    "\n",
    "            # First upsample block: (128, 7, 7) → (128, 14, 14)\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            # Conv2D(128, 3, padding='same', activation='relu')\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128, momentum=0.8),\n",
    "\n",
    "            # Second upsample block: (128, 14, 14) → (128, 28, 28)\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            # Conv2D(64, 3, padding='same', activation='relu')\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64, momentum=0.8),\n",
    "\n",
    "            # Output layer: (64, 28, 28) → (1, 28, 28), tanh maps to [-1, 1]\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z, labels):\n",
    "        # Embed the label and multiply element-wise with z (multiplicative conditioning)\n",
    "        label_embed = self.label_embedding(labels).squeeze(1)  # (batch, latent_dim)\n",
    "        conditioned = z * label_embed                           # (batch, latent_dim)\n",
    "\n",
    "        # Pass through the dense layer, then reshape to (batch, 128, 7, 7) for the conv layers\n",
    "        x = self.model[0](conditioned)  # Linear\n",
    "        x = self.model[1](x)            # ReLU\n",
    "        x = x.view(-1, 128, 7, 7)\n",
    "\n",
    "        # Pass through the remaining conv/upsample layers\n",
    "        x = self.model[2:](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Instantiate and move to device\n",
    "g_model = Generator().to(device)\n",
    "print(g_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c856fd90",
   "metadata": {},
   "source": [
    "## 4. Discriminator\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=NUM_CLASSES, use_sigmoid=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.use_sigmoid = use_sigmoid\n",
    "\n",
    "        # Embed the class label into a vector of size 28*28 (one full image channel)\n",
    "        self.label_embedding = nn.Embedding(num_classes, 28 * 28)\n",
    "\n",
    "        # Main sequential network that classifies the concatenated input\n",
    "        self.model = nn.Sequential(\n",
    "            # Input is (2, 28, 28): image channel + label channel\n",
    "            nn.Conv2d(2, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            # Second conv block: (32, 14, 14) → (64, 7, 7)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            # Flatten: (64, 7, 7) → (64*7*7) = (3136)\n",
    "            nn.Flatten(),\n",
    "\n",
    "            # Dense(512, activation='relu')\n",
    "            nn.Linear(64 * 7 * 7, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            # Output: single value (sigmoid applied conditionally)\n",
    "            nn.Linear(512, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, labels):\n",
    "        # Embed label to 784 dims, reshape to a spatial map (1, 28, 28)\n",
    "        label_embed = self.label_embedding(labels).squeeze(1)\n",
    "        label_embed = label_embed.view(-1, 1, 28, 28)\n",
    "\n",
    "        # Concatenate image and label map along channel axis\n",
    "        x = torch.cat([img, label_embed], dim=1)\n",
    "\n",
    "        x = self.model(x)\n",
    "        \n",
    "        if self.use_sigmoid:\n",
    "            x = torch.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb7733",
   "metadata": {},
   "source": [
    "# 5. Loss and Optimizers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loss strategy\n",
    "loss_strategy = get_loss_strategy(LOSS_STRATEGY, device)\n",
    "print(f\"Using loss strategy: {LOSS_STRATEGY} (sigmoid: {loss_strategy.use_sigmoid})\")\n",
    "\n",
    "# Instantiate models\n",
    "g_model = Generator().to(device)\n",
    "d_model = Discriminator(use_sigmoid=loss_strategy.use_sigmoid).to(device)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_g = optim.Adam(g_model.parameters(), lr=0.001)\n",
    "optimizer_d = optim.Adam(d_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9867640",
   "metadata": {},
   "source": [
    "# 5A. Live Training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9debcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIVE_MONITOR:\n",
    "    from bin.gan_monitor import start_server, emit_frames, emit_done\n",
    "    start_server(port=8992)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cec7284",
   "metadata": {},
   "source": [
    "# 6. Training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d16e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(images, labels, rows, cols):\n",
    "    \"\"\"Plots a grid of generated images with their class labels.\"\"\"\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    for i in range(rows * cols):\n",
    "        img = images[i].detach().cpu().numpy().reshape(28, 28)\n",
    "        ax = fig.add_subplot(rows, cols, i + 1)\n",
    "        ax.set_title(str(labels[i].item()))\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    # Fixed test noise and labels — used every SAVE_INTERVAL to visualize progress\n",
    "    samples_test = torch.randn(16, LATENT_DIM, device=device)\n",
    "    labels_test = torch.randint(0, 10, (16, 1), device=device)\n",
    "\n",
    "    losses = {\"G\": [], \"D\": []}\n",
    "\n",
    "    # Create an infinite iterator over the DataLoader\n",
    "    data_iter = iter(train_loader)\n",
    "\n",
    "    for step in range(NUM_STEPS):\n",
    "\n",
    "        # --- Get a real batch from DataLoader ---\n",
    "        try:\n",
    "            real_imgs, batch_labels = next(data_iter)\n",
    "        except StopIteration:\n",
    "            data_iter = iter(train_loader)\n",
    "            real_imgs, batch_labels = next(data_iter)\n",
    "\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        batch_labels = batch_labels.unsqueeze(1).to(device)\n",
    "\n",
    "        # --- Generate fake images ---\n",
    "        noise = torch.randn(BATCH_SIZE, LATENT_DIM, device=device)\n",
    "        fake_imgs = g_model(noise, batch_labels)\n",
    "\n",
    "        # --- Train Discriminator ---\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        d_real_out = d_model(real_imgs, batch_labels)\n",
    "        d_loss_real = loss_strategy.d_loss_real(d_real_out)\n",
    "\n",
    "        d_fake_out = d_model(fake_imgs.detach(), batch_labels)\n",
    "        d_loss_fake = loss_strategy.d_loss_fake(d_fake_out)\n",
    "\n",
    "        d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # --- Train Generator ---\n",
    "        optimizer_g.zero_grad()\n",
    "\n",
    "        z = torch.randn(BATCH_SIZE, LATENT_DIM, device=device)\n",
    "        gen_labels = torch.randint(0, 10, (BATCH_SIZE, 1), device=device)\n",
    "\n",
    "        gen_imgs = g_model(z, gen_labels)\n",
    "        g_out = d_model(gen_imgs, gen_labels)\n",
    "\n",
    "        g_loss = loss_strategy.g_loss(g_out)\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        # --- Logging ---\n",
    "        losses[\"G\"].append(g_loss.item())\n",
    "        losses[\"D\"].append(d_loss.item())\n",
    "\n",
    "        if step % SAVE_INTERVAL == 0:\n",
    "            print(f\"Step {step} — D loss: {d_loss.item():.4f}, G loss: {g_loss.item():.4f}\")\n",
    "            with torch.no_grad():\n",
    "                results = g_model(samples_test, labels_test)\n",
    "            plot_image(results, labels_test, 4, 4)\n",
    "\n",
    "        if LIVE_MONITOR and step % EMIT_INTERVAL == 0:\n",
    "            with torch.no_grad():\n",
    "                results = g_model(samples_test, labels_test)\n",
    "            emit_frames(results, labels_test, step, g_loss.item(), d_loss.item())\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "losses = train_model()\n",
    "\n",
    "if LIVE_MONITOR:\n",
    "    emit_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50a957",
   "metadata": {},
   "source": [
    "# 7. Loss Reporting\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses):\n",
    "    \"\"\"Plots generator and discriminator losses over training steps.\"\"\"\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses[\"D\"], label=\"Discriminator\", alpha=0.7)\n",
    "    plt.plot(losses[\"G\"], label=\"Generator\", alpha=0.7)\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training Losses\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22825292",
   "metadata": {},
   "source": [
    "# 8. Per-class Grid\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdd148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_per_class(g_model, rows_per_class=5):\n",
    "    \"\"\"Generates a grid with one column per digit class (0-9).\"\"\"\n",
    "    fig, axes = plt.subplots(rows_per_class, 10, figsize=(15, 8))\n",
    "\n",
    "    for digit in range(10):\n",
    "        noise = torch.randn(rows_per_class, LATENT_DIM, device=device)\n",
    "        labels = torch.full((rows_per_class, 1), digit, device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = g_model(noise, labels)\n",
    "\n",
    "        for row in range(rows_per_class):\n",
    "            img = images[row].cpu().numpy().reshape(28, 28)\n",
    "            axes[row, digit].imshow(img, cmap='gray')\n",
    "            axes[row, digit].axis('off')\n",
    "\n",
    "            # Column headers on the first row only\n",
    "            if row == 0:\n",
    "                axes[row, digit].set_title(str(digit))\n",
    "\n",
    "    fig.suptitle(\"Generated Samples Per Class\", fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_per_class(g_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e14742",
   "metadata": {},
   "source": [
    "# 9. Evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    \"\"\"Computes FID and KID between real MNIST images and generated images.\"\"\"\n",
    "\n",
    "    # --- Initialize metrics ---\n",
    "    # Both use Inception-v3 features internally\n",
    "    # feature=2048 uses the final pooling layer (standard for FID/KID)\n",
    "    fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "    kid = KernelInceptionDistance(feature=2048, subset_size=100).to(device)\n",
    "\n",
    "    # --- Prepare real images ---\n",
    "    # Sample NUM_EVAL_SAMPLES random indices from the training set\n",
    "    idx = np.random.randint(0, len(train_dataset), NUM_EVAL_SAMPLES)\n",
    "\n",
    "    # Process in batches to avoid OOM\n",
    "    batch_size = 256\n",
    "    for i in range(0, NUM_EVAL_SAMPLES, batch_size):\n",
    "        batch_idx = idx[i:i + batch_size]\n",
    "\n",
    "        # Stack real images: (batch, 1, 28, 28) in [-1, 1]\n",
    "        real_batch = torch.stack([train_dataset[j][0] for j in batch_idx])\n",
    "\n",
    "        # Inception expects 3-channel uint8 [0, 255] at minimum 299x299\n",
    "        # Denormalize: [-1, 1] → [0, 1] → [0, 255]\n",
    "        real_batch = ((real_batch + 1) / 2 * 255).clamp(0, 255).to(torch.uint8)\n",
    "\n",
    "        # Convert grayscale to RGB by repeating the single channel 3 times\n",
    "        real_batch = real_batch.repeat(1, 3, 1, 1)\n",
    "\n",
    "        # Resize from 28x28 to 299x299 (Inception's expected input size)\n",
    "        real_batch = torch.nn.functional.interpolate(\n",
    "            real_batch.float(), size=(299, 299), mode='bilinear', align_corners=False\n",
    "        ).to(torch.uint8).to(device)\n",
    "\n",
    "        # Feed real images into both metrics\n",
    "        fid.update(real_batch, real=True)\n",
    "        kid.update(real_batch, real=True)\n",
    "\n",
    "    # --- Generate fake images ---\n",
    "    for i in range(0, NUM_EVAL_SAMPLES, batch_size):\n",
    "        current_batch = min(batch_size, NUM_EVAL_SAMPLES - i)\n",
    "\n",
    "        noise = torch.randn(current_batch, LATENT_DIM, device=device)\n",
    "        labels = torch.randint(0, 10, (current_batch, 1), device=device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_batch = g_model(noise, labels)\n",
    "\n",
    "        # Same preprocessing: denormalize → RGB → resize\n",
    "        fake_batch = ((fake_batch + 1) / 2 * 255).clamp(0, 255).to(torch.uint8)\n",
    "        fake_batch = fake_batch.repeat(1, 3, 1, 1)\n",
    "        fake_batch = torch.nn.functional.interpolate(\n",
    "            fake_batch.float(), size=(299, 299), mode='bilinear', align_corners=False\n",
    "        ).to(torch.uint8).to(device)\n",
    "\n",
    "        fid.update(fake_batch, real=False)\n",
    "        kid.update(fake_batch, real=False)\n",
    "\n",
    "    # --- Compute scores ---\n",
    "    fid_score = fid.compute().item()\n",
    "    kid_mean, kid_std = kid.compute()\n",
    "\n",
    "    print(f\"FID: {fid_score:.2f}\")\n",
    "    print(f\"KID: {kid_mean.item():.4f} ± {kid_std.item():.4f}\")\n",
    "\n",
    "    return fid_score, kid_mean.item(), kid_std.item()\n",
    "\n",
    "\n",
    "fid_score, kid_mean, kid_std = evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8817863c",
   "metadata": {},
   "source": [
    "# 10. Model Saving\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8507f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_models():\n",
    "    \"\"\"Saves generator and discriminator state dicts.\"\"\"\n",
    "    os.makedirs(MODEL_OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "    # torch.save() serializes the state_dict (all learned parameters)\n",
    "    # This is the recommended way to save in PyTorch (saving the full model object)\n",
    "    torch.save(g_model.state_dict(), os.path.join(MODEL_OUTPUT_PATH, f'{G_MODEL_NAME}.pt'))\n",
    "    torch.save(d_model.state_dict(), os.path.join(MODEL_OUTPUT_PATH, f'{D_MODEL_NAME}.pt'))\n",
    "    print(\"Models saved.\")\n",
    "\n",
    "save_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63e5cf",
   "metadata": {},
   "source": [
    "# 11. Single-Image Inference\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a digit from 0-9\n",
    "digit = 3\n",
    "\n",
    "# Generate a single image for the chosen digit\n",
    "z = torch.randn(1, LATENT_DIM, device=device)\n",
    "label = torch.tensor([[digit]], device=device)\n",
    "\n",
    "# No gradient tracking needed during inference\n",
    "with torch.no_grad():\n",
    "    generated = g_model(z, label)\n",
    "\n",
    "# Convert from (1, 1, 28, 28) GPU tensor to (28, 28) numpy array for plotting\n",
    "img = generated[0].cpu().numpy().reshape(28, 28)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(f\"Generated digit: {digit}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_taap_p1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
